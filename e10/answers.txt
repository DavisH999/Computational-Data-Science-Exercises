1. How long did your reddit_averages.py take with
(1) the reddit-0 data set and effectively no work,
    4.43s user 1.84s system 244% cpu 2.565 total
(2) no schema specified and not caching (on reddit-2 for this and the rest),
    17.89s user 2.53s system 172% cpu 11.843 total
(3) with a schema but not caching,
    14.57s user 2.43s system 193% cpu 8.809 total
(4) with both a schema and caching the twice-used DataFrame?
    12.34s user 2.36s system 206% cpu 7.111 total
[The reddit-0 test is effectively measuring the Spark startup time, so we can see how long it takes to do the actual work on reddit-2 in the best/worst cases.]

2. Based on the above, does it look like most of the time taken to process the reddit-2 data set is in reading the files, or calculating the averages?
    Yes.I think so.

3. Where did you use .cache() in your wikipedia_popular.py? [Hint: the answer had better be “once”… but where?]
    Above the groupBy()
